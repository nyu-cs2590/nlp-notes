# Natural Language Processing
**CSCI-GA 2590, New York University, Fall 2020**

## Logistics
- Tentative format: online lectures with in-person discussions
- Lectures: Tue 7:10pm-9pm (on Zoom)
- Instructor: [He He](https://hhexiy.github.io)
- TAs: TBD
- Office hours: TBD

## Important dates

## Course information
How can we teach machines to understand language so that they can answer our queries, extract information from textual data, or even have a conversation with us?
The primary goal of this course is to provide students with the principles and tools needed to solve a variety of NLP problems.
We will focus on data-driven methods,
including classification, sequence labeling, structured prediction, unsupervised learning, and deep learning.
Specific applications include text classification, constituent parsing, semantic parsing, and generation.

### Prerequisites
Students are expected to have solid mathematic background and programming skills.

- Probability, statistics, linear algebra (DS-GA.1002, MATH-UA.140, MATH-UA.235) 
- Algorithms and data structure (CSCI-UA.102)
- Machine learning (DS-GA.1003, CSCI-UA.0473)

### Resources
**Textbook:** There is no required textbook. Course notes/slides should be sufficient.
Some lectures will be based on the following books (available freely online):

- [Dan Jurafsky and James H. Martin. Speech and Language Processing.](https://web.stanford.edu/~jurafsky/slp3/) A classic textbook covering both traditional and modern approaches to NLP.
- [Jacob Eisenstein. Introduction to Natural Language Processing.](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf) A comprehensive reference with additional coverage on relevant topics in linguistics and slightly more advanced topics in machine learning.
- [Yoav Goldberg. Neural Network Methods for Natural Language Processing.](https://u.cs.biu.ac.il/~yogo/nnlp.pdf) Covers neural network models for NLP.

**Background**: Here are some useful materials if you want to review the background knowledge.

- Probability and optimization in the appendix of Eisenstein's book.
- [Notes](https://cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/notes.html) for DS-GA.1002.
- [A short guide to linguistics](https://faculty.washington.edu/ebender/100things-sem_prag.html) for NLPers by Bender. 



```toc
:maxdepth: 2
:hidden:

schedule
coursework
notes/index.md
```
